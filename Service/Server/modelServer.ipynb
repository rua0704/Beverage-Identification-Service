{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "modelServer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "091af985bee84b7285f9b5b8f6f73a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a480c4d2c6e43639f6147ff2fc87ae9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_664844c4e7d64aa59661e7d5a58aae2f",
              "IPY_MODEL_141da906b7c241fea629e120b5709832",
              "IPY_MODEL_62a1cfad9b9d4fa5af4a28ea6f849324"
            ]
          }
        },
        "6a480c4d2c6e43639f6147ff2fc87ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "664844c4e7d64aa59661e7d5a58aae2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69235291817b4c2187ac16fdaf26f8d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f32f560758ac425da8db5269ffc8f0c1"
          }
        },
        "141da906b7c241fea629e120b5709832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bcdb0844095c4359aa712563bb346585",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3224e71fa8ed4fa0a04e3a1c665bafbf"
          }
        },
        "62a1cfad9b9d4fa5af4a28ea6f849324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3fee67f23e2c4f62a3680bbf96ccc889",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 125MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c54c93b8d34400e987db41d7100ab28"
          }
        },
        "69235291817b4c2187ac16fdaf26f8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f32f560758ac425da8db5269ffc8f0c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcdb0844095c4359aa712563bb346585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3224e71fa8ed4fa0a04e3a1c665bafbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fee67f23e2c4f62a3680bbf96ccc889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c54c93b8d34400e987db41d7100ab28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1099a74a",
        "outputId": "5aa66856-3255-4219-be17-a23017813f5d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "id": "1099a74a",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24bb4a71"
      },
      "source": [
        "import os\n",
        "import torch.utils.data\n",
        "from torch.nn import DataParallel\n",
        "from datetime import datetime\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms"
      ],
      "id": "24bb4a71",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63a6d094"
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "PROPOSAL_NUM = 6\n",
        "CAT_NUM = 4\n",
        "INPUT_SIZE = (224, 224)\n",
        "LR = 0.001\n",
        "WD = 1e-4\n",
        "SAVE_FREQ = 1\n",
        "resume = ''\n",
        "test_model = './drive/MyDrive/data_100/model/final_3.ckpt'\n",
        "save_dir = '/model'"
      ],
      "id": "63a6d094",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5fda7ce"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import logging\n",
        "\n",
        "term_width = 80\n",
        "term_width = int(term_width)\n",
        "\n",
        "TOTAL_BAR_LENGTH = 40.\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "\n",
        "\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH * current / total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width - int(TOTAL_BAR_LENGTH) - len(msg) - 3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width - int(TOTAL_BAR_LENGTH / 2)):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current + 1, total))\n",
        "\n",
        "    if current < total - 1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600 / 24)\n",
        "    seconds = seconds - days * 3600 * 24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours * 3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes * 60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds * 1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f\n",
        "\n",
        "\n",
        "def init_log(output_dir):\n",
        "    logging.basicConfig(level=logging.DEBUG,\n",
        "                        format='%(asctime)s %(message)s',\n",
        "                        datefmt='%Y%m%d-%H:%M:%S',\n",
        "                        filename=os.path.join(output_dir, 'log.log'),\n",
        "                        filemode='w')\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.INFO)\n",
        "    logging.getLogger('').addHandler(console)\n",
        "    return logging\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pass"
      ],
      "id": "f5fda7ce",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63e34c21"
      },
      "source": [
        "import numpy as np\n",
        "#from config import INPUT_SIZE\n",
        "\n",
        "_default_anchors_setting = (#3부분?!!\n",
        "    dict(layer='p3', stride=32, size=48, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
        "    dict(layer='p4', stride=64, size=96, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
        "    dict(layer='p5', stride=128, size=192, scale=[1, 2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
        ")\n",
        "\n",
        "\n",
        "def generate_default_anchor_maps(anchors_setting=None, input_shape=INPUT_SIZE):\n",
        "    \"\"\"\n",
        "    generate default anchor\n",
        "    :param anchors_setting: all informations of anchors\n",
        "    :param input_shape: shape of input images, e.g. (h, w)\n",
        "    :return: center_anchors: # anchors * 4 (oy, ox, h, w)\n",
        "             edge_anchors: # anchors * 4 (y0, x0, y1, x1)\n",
        "             anchor_area: # anchors * 1 (area)\n",
        "    \"\"\"\n",
        "    if anchors_setting is None:\n",
        "        anchors_setting = _default_anchors_setting\n",
        "\n",
        "    center_anchors = np.zeros((0, 4), dtype=np.float32)\n",
        "    edge_anchors = np.zeros((0, 4), dtype=np.float32)\n",
        "    anchor_areas = np.zeros((0,), dtype=np.float32)\n",
        "    input_shape = np.array(input_shape, dtype=int)\n",
        "\n",
        "    for anchor_info in anchors_setting:\n",
        "\n",
        "        stride = anchor_info['stride']\n",
        "        size = anchor_info['size']\n",
        "        scales = anchor_info['scale']\n",
        "        aspect_ratios = anchor_info['aspect_ratio']\n",
        "\n",
        "        output_map_shape = np.ceil(input_shape.astype(np.float32) / stride) #np.ceil:소수점 올림!!->정수\n",
        "        output_map_shape = output_map_shape.astype(np.int)\n",
        "        output_shape = tuple(output_map_shape) + (4,)\n",
        "        ostart = stride / 2.\n",
        "        oy = np.arange(ostart, ostart + stride * output_shape[0], stride)\n",
        "        oy = oy.reshape(output_shape[0], 1)\n",
        "        ox = np.arange(ostart, ostart + stride * output_shape[1], stride)\n",
        "        ox = ox.reshape(1, output_shape[1])\n",
        "        center_anchor_map_template = np.zeros(output_shape, dtype=np.float32)\n",
        "        center_anchor_map_template[:, :, 0] = oy\n",
        "        center_anchor_map_template[:, :, 1] = ox\n",
        "        for scale in scales:\n",
        "            for aspect_ratio in aspect_ratios:\n",
        "                center_anchor_map = center_anchor_map_template.copy()\n",
        "                center_anchor_map[:, :, 2] = size * scale / float(aspect_ratio) ** 0.5\n",
        "                center_anchor_map[:, :, 3] = size * scale * float(aspect_ratio) ** 0.5\n",
        "\n",
        "                edge_anchor_map = np.concatenate((center_anchor_map[..., :2] - center_anchor_map[..., 2:4] / 2.,\n",
        "                                                  center_anchor_map[..., :2] + center_anchor_map[..., 2:4] / 2.),\n",
        "                                                 axis=-1)\n",
        "                anchor_area_map = center_anchor_map[..., 2] * center_anchor_map[..., 3]\n",
        "                center_anchors = np.concatenate((center_anchors, center_anchor_map.reshape(-1, 4)))\n",
        "                edge_anchors = np.concatenate((edge_anchors, edge_anchor_map.reshape(-1, 4)))\n",
        "                anchor_areas = np.concatenate((anchor_areas, anchor_area_map.reshape(-1)))\n",
        "\n",
        "    return center_anchors, edge_anchors, anchor_areas\n",
        "\n",
        "# IoU: https://deep-learning-study.tistory.com/402 \n",
        "# predicted bounding box가 ground-truth bounding box와 얼마나 일치하는지 측정하기 위한 평가 지표를 정의\n",
        "# area of overlap / area of union\n",
        "def hard_nms(cdds, topn=10, iou_thresh=0.25): #non-maximum suppression\n",
        "    #object detector가 예측한 bounding box 중에서 정확한 bounding box를 선택하도록 하는 기법\n",
        "    #iou_thresh:한계점\n",
        "    if not (type(cdds).__module__ == 'numpy' and len(cdds.shape) == 2 and cdds.shape[1] >= 5):\n",
        "        raise TypeError('edge_box_map should be N * 5+ ndarray')\n",
        "\n",
        "    cdds = cdds.copy()\n",
        "    indices = np.argsort(cdds[:, 0])#모든 행 첫번째 열 #np.argsort:numpy array 정렬 #그래서 행이 총 3개면 [0,1,2]임\n",
        "    cdds = cdds[indices]#cdds 그대로 가져옴 ###########이거 왜 필요하죠..? 그냥 cdds인데...\n",
        "    cdd_results = []\n",
        "\n",
        "    res = cdds\n",
        "\n",
        "    while res.any():\n",
        "        cdd = res[-1]# 마지막 행\n",
        "        cdd_results.append(cdd)\n",
        "        if len(cdd_results) == topn:\n",
        "            return np.array(cdd_results)\n",
        "        res = res[:-1] # 마지막 행 제외\n",
        "\n",
        "        start_max = np.maximum(res[:, 1:3], cdd[1:3])# 두 개의 array에 대해 동일한 위치의 성분끼리 비교하여 최대값 또는 최소값 계산\n",
        "        end_min = np.minimum(res[:, 3:5], cdd[3:5])\n",
        "        lengths = end_min - start_max\n",
        "        intersec_map = lengths[:, 0] * lengths[:, 1]\n",
        "        intersec_map[np.logical_or(lengths[:, 0] < 0, lengths[:, 1] < 0)] = 0\n",
        "        iou_map_cur = intersec_map / ((res[:, 3] - res[:, 1]) * (res[:, 4] - res[:, 2]) + (cdd[3] - cdd[1]) * (\n",
        "            cdd[4] - cdd[2]) - intersec_map)\n",
        "        res = res[iou_map_cur < iou_thresh]\n",
        "\n",
        "    return np.array(cdd_results)"
      ],
      "id": "63e34c21",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41d90592"
      },
      "source": [
        "\n",
        "#core폴더의 resnet.py\n",
        "#resnet\n",
        "\n",
        "#Batch normalization- Gradient 라는 것이 결국 미분값 즉 변화량을 의미하는데 \n",
        "                    #이 변화량이 매우 작아지거나(Vanishing) 커진다면(Exploding) 신경망을 효과적으로 학습시키지 못하고, \n",
        "                    #Error rate 가 낮아지지 않고 수렴해버리는 문제가 발생\n",
        "                    #기본적으로 정규화를 하는 이유는 학습을 더 빨리 하기 위해서 or Local optimum 문제에 빠지는 가능성을 줄이기 위해 사용\n",
        "                    # 배치 정규화는 평균과 분산을 조정하는 과정이 별도의 과정으로 떼어진 것이 아니라, \n",
        "                        #신경망 안에 포함되어 학습 시 평균과 분산을 조정하는 과정\n",
        "## https://m.blog.naver.com/laonple/220808903260\n",
        "\n",
        "#resnet의 residual learning: residual mapping (잔차 매핑) 이 기존의 mapping보다 optimize(최적화) 하기 쉽다는 것을 가정\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample# downsampling:차원을 줄여서 적은 메모리로 깊은 convolution을 할 수 있게 한다. \n",
        "        # 보통 stride를 2 이상으로 하는 convolution을 사용하거나 pooling을 사용한다. \n",
        "        # 이 과정을 거치면 어쩔 수 없이 feature의 정보를 잃게된다.\n",
        "        # https://m.blog.naver.com/9709193/221979612209\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    # 1x1-> 3x3 -> 1x1\n",
        "    \n",
        "    # Convolution Parameters = Kernel Size x Kernel Size x Input Channel x Output Channel\n",
        "    #1x1 Convolution: 연산량이 작기 때문에 Feature Map(Output Channel)을 줄이거나 키울 때 사용\n",
        "    #차원, 채널 축소 후 공간적 특성 추출(3x3 Convolution이 연산량이 9배 많기 때문에), 채널 증가, parameters 감소\n",
        "\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)# If True, adds a learnable bias to the output.\n",
        "        ## BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정합니다.\n",
        "        ## https://deep-learning-study.tistory.com/534\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)# num_features – C dimension from an expected input of size (N, C, H, W)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) #https://guru.tistory.com/70 예시:(1,1,64,64)->(1,1,32,32)\n",
        "                                                                            #maxpool2d(2)일 때\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels#################\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        feature1 = x\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = nn.Dropout(p=0.5)(x)\n",
        "        feature2 = x\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x, feature1, feature2\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model"
      ],
      "id": "41d90592",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3faa9fe"
      },
      "source": [
        "#core 폴더의 model.py\n",
        "\n",
        "from torch import nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "#from core import resnet\n",
        "import numpy as np\n",
        "#from core.anchors import generate_default_anchor_maps, hard_nms\n",
        "#from config import CAT_NUM, PROPOSAL_NUM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ProposalNet(nn.Module): # attention proposal network / regional proposal network (RPN)##############################\n",
        "    def __init__(self):\n",
        "        super(ProposalNet, self).__init__()\n",
        "        self.down1 = nn.Conv2d(2048, 128, 3, 1, 1)#torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, \n",
        "                                                  #padding=0, dilation=1, groups=1, bias=True, \n",
        "                                                  #padding_mode='zeros', device=None, dtype=None)\n",
        "        self.down2 = nn.Conv2d(128, 128, 3, 2, 1)\n",
        "        self.down3 = nn.Conv2d(128, 128, 3, 2, 1)\n",
        "        self.ReLU = nn.ReLU()\n",
        "        self.tidy1 = nn.Conv2d(128, 6, 1, 1, 0)\n",
        "        self.tidy2 = nn.Conv2d(128, 6, 1, 1, 0)\n",
        "        self.tidy3 = nn.Conv2d(128, 9, 1, 1, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        d1 = self.ReLU(self.down1(x))\n",
        "        d2 = self.ReLU(self.down2(d1))\n",
        "        d3 = self.ReLU(self.down3(d2))\n",
        "        t1 = self.tidy1(d1).view(batch_size, -1)\n",
        "        t2 = self.tidy2(d2).view(batch_size, -1)\n",
        "        t3 = self.tidy3(d3).view(batch_size, -1)\n",
        "        return torch.cat((t1, t2, t3), dim=1)\n",
        "\n",
        "\n",
        "class attention_net(nn.Module):\n",
        "    def __init__(self, topN=4):\n",
        "        super(attention_net, self).__init__()\n",
        "        self.pretrained_model = resnet50(pretrained=True)\n",
        "        self.pretrained_model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        #avg_pool2d에서 풀링 작업을 위한 커널과 보폭 크기를 정의하고 함수는 모든 유효한 입력에 대해 해당 작업을 수행합니다. \n",
        "        #예를 들어 kernel=3, stride=2, padding=0인 avg_pool2d는 5x5 텐서를 3x3 텐서로, 7x7 텐서를 4x4 텐서로 줄입니다.(HxW)\n",
        "#adaptive_avg_pool2d에서 필요한 출력 크기를 정의합니다. 풀링 작업이 끝나면 pytorch가 이를 수행하는 데 사용할 풀링 매개변수를 유추합니다. \n",
        "#예를 들어 출력 크기가(3,3)인 adaptive_avg_pool2d는 5x5 및 7x7 텐서를 모두 3x3 텐서로 줄입니다.\n",
        "        self.pretrained_model.fc = nn.Linear(512 * 4, 105) # nn.Linear(input_dim, output_dim)\n",
        "        self.proposal_net = ProposalNet()\n",
        "        self.topN = topN\n",
        "        self.concat_net = nn.Linear(2048 * (CAT_NUM + 1), 105)\n",
        "        self.partcls_net = nn.Linear(512 * 4, 105) #4 * 4 * 128\n",
        "        _, edge_anchors, _ = generate_default_anchor_maps()\n",
        "        self.pad_side = 224\n",
        "        self.edge_anchors = (edge_anchors + 224).astype(np.int)\n",
        "\n",
        "    def forward(self, x):\n",
        "        resnet_out, rpn_feature, feature = self.pretrained_model(x)\n",
        "        x_pad = F.pad(x, (self.pad_side, self.pad_side, self.pad_side, self.pad_side), mode='constant', value=0)\n",
        "        batch = x.size(0)\n",
        "        # we will reshape rpn to shape: batch * nb_anchor\n",
        "        rpn_score = self.proposal_net(rpn_feature.detach())\n",
        "        all_cdds = [\n",
        "            np.concatenate((x.reshape(-1, 1), self.edge_anchors.copy(), np.arange(0, len(x)).reshape(-1, 1)), axis=1)\n",
        "            for x in rpn_score.data.cpu().numpy()]\n",
        "        top_n_cdds = [hard_nms(x, topn=self.topN, iou_thresh=0.25) for x in all_cdds]\n",
        "        top_n_cdds = np.array(top_n_cdds)\n",
        "        top_n_index = top_n_cdds[:, :, -1].astype(np.int)\n",
        "        top_n_index = torch.from_numpy(top_n_index).cuda()\n",
        "        top_n_prob = torch.gather(rpn_score, dim=1, index=top_n_index)\n",
        "        part_imgs = torch.zeros([batch, self.topN, 3, 224, 224]).cuda()\n",
        "        for i in range(batch):\n",
        "            for j in range(self.topN):\n",
        "                [y0, x0, y1, x1] = top_n_cdds[i][j, 1:5].astype(np.int)\n",
        "                part_imgs[i:i + 1, j] = F.interpolate(x_pad[i:i + 1, :, y0:y1, x0:x1], size=(224, 224), mode='bilinear',\n",
        "                                                      align_corners=True)\n",
        "        part_imgs = part_imgs.view(batch * self.topN, 3, 224, 224)\n",
        "        _, _, part_features = self.pretrained_model(part_imgs.detach())\n",
        "        part_feature = part_features.view(batch, self.topN, -1)\n",
        "        part_feature = part_feature[:, :CAT_NUM, ...].contiguous()\n",
        "        part_feature = part_feature.view(batch, -1)\n",
        "        # concat_logits have the shape: B*200\n",
        "        concat_out = torch.cat([part_feature, feature], dim=1)\n",
        "        concat_logits = self.concat_net(concat_out)\n",
        "        raw_logits = resnet_out\n",
        "        # part_logits have the shape: B*N*200\n",
        "        part_logits = self.partcls_net(part_features).view(batch, self.topN, -1)\n",
        "        return [raw_logits, concat_logits, part_logits, top_n_index, top_n_prob]\n",
        "\n",
        "\n",
        "def list_loss(logits, targets):\n",
        "    temp = F.log_softmax(logits, -1)\n",
        "    loss = [-temp[i][targets[i].item()] for i in range(logits.size(0))]\n",
        "    return torch.stack(loss)\n",
        "\n",
        "\n",
        "def ranking_loss(score, targets, proposal_num=PROPOSAL_NUM):\n",
        "    loss = Variable(torch.zeros(1).cuda())\n",
        "    batch_size = score.size(0)\n",
        "    for i in range(proposal_num):\n",
        "        targets_p = (targets > targets[:, i].unsqueeze(1)).type(torch.cuda.FloatTensor)\n",
        "        pivot = score[:, i].unsqueeze(1)\n",
        "        loss_p = (1 - pivot + score) * targets_p\n",
        "        loss_p = torch.sum(F.relu(loss_p))\n",
        "        loss += loss_p\n",
        "    return loss / batch_size"
      ],
      "id": "f3faa9fe",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20788fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "091af985bee84b7285f9b5b8f6f73a21",
            "6a480c4d2c6e43639f6147ff2fc87ae9",
            "664844c4e7d64aa59661e7d5a58aae2f",
            "141da906b7c241fea629e120b5709832",
            "62a1cfad9b9d4fa5af4a28ea6f849324",
            "69235291817b4c2187ac16fdaf26f8d1",
            "f32f560758ac425da8db5269ffc8f0c1",
            "bcdb0844095c4359aa712563bb346585",
            "3224e71fa8ed4fa0a04e3a1c665bafbf",
            "3fee67f23e2c4f62a3680bbf96ccc889",
            "3c54c93b8d34400e987db41d7100ab28"
          ]
        },
        "outputId": "5c139e10-5ac6-4f1d-a5bc-1625c89a5890"
      },
      "source": [
        "# define model\n",
        "net = attention_net(topN=PROPOSAL_NUM)\n",
        "ckpt = torch.load(test_model)\n",
        "net.load_state_dict(ckpt['net_state_dict'])\n",
        "net = net.cuda()\n",
        "net = DataParallel(net)\n",
        "creterion = torch.nn.CrossEntropyLoss()"
      ],
      "id": "20788fab",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "091af985bee84b7285f9b5b8f6f73a21",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "905a63da"
      },
      "source": [
        "import torch.utils\n",
        "\n",
        "tf = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "id": "905a63da",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3127e2c0"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import PIL"
      ],
      "id": "3127e2c0",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0f9a878"
      },
      "source": [
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "data_dir = './drive/MyDrive/data_100'\n",
        "test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'img_list'), transforms_test)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=1 , shuffle=True, num_workers=2)"
      ],
      "id": "e0f9a878",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1a6f2b7"
      },
      "source": [
        "class_names = test_datasets.classes"
      ],
      "id": "d1a6f2b7",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b29d65c8",
        "outputId": "7b79a1b5-430e-4b2a-a4e3-e47fd006747c"
      },
      "source": [
        "print(len(class_names))"
      ],
      "id": "b29d65c8",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3347bc77"
      },
      "source": [
        "class_prices = []\n",
        "for i in range(0, len(class_names)):\n",
        "  class_prices.append(1000 + (i % 8) * 100)"
      ],
      "id": "3347bc77",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fe61a29",
        "outputId": "96d2e6af-f74d-49e0-cec2-5ae645d4108c"
      },
      "source": [
        "# 필요한 라이브러리 설치하기\n",
        "!pip install flask-ngrok"
      ],
      "id": "6fe61a29",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6705e416"
      },
      "source": [
        "import io\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, jsonify, request\n",
        "import base64\n",
        "from PIL import Image\n",
        "\n",
        "net.eval()\n",
        "\n",
        "addList = \"\"\n",
        "\n",
        "# 이미지를 읽어 결과를 반환하는 함수\n",
        "def get_prediction(image_bytes):\n",
        "    image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
        "    # image = tf(image).unsqueeze(0).to(device)\n",
        "    image = tf(image)\n",
        "    image = image.unsqueeze(dim=0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _, concat_logits, _, _, _ = net(image)\n",
        "\n",
        "        _, concat_predict = torch.max(concat_logits, 1)\n",
        "        \n",
        "        print(class_names[concat_predict[0]])\n",
        "    return class_names[concat_predict[0]], class_prices[concat_predict[0]]\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def predict():\n",
        "    global addList\n",
        "    if request.method == 'POST':\n",
        "\n",
        "        value = request.form['file']\n",
        "\n",
        "        value = value.split(',')[1]\n",
        "        value = base64.b64decode(value)\n",
        "\n",
        "        # 분류 결과 확인 및 클라이언트에게 결과 반환\n",
        "        class_name, class_price = get_prediction(image_bytes=value)\n",
        "        print(\"결과:\", {'class_name': class_name})\n",
        "\n",
        "        result_t = {\n",
        "            'result' : str(class_name).split('_')[1],\n",
        "            'price'  : class_price\n",
        "        }\n",
        "        addList += str(class_name).split('_')[1] + \",\" + str(class_price) + \".\"\n",
        "        result = jsonify(result_t)\n",
        "        result.headers[\"Access-Control-Allow-Origin\"] = \"*\"\n",
        "        return result\n",
        "\n",
        "@app.route('/list', methods=['POST'])\n",
        "def sendlist():\n",
        "    global addList\n",
        "    if request.method == 'POST':\n",
        "        result = {\n",
        "            'result' : addList\n",
        "        }\n",
        "        result = jsonify(result)\n",
        "        result.headers[\"Access-Control-Allow-Origin\"] = \"*\"\n",
        "        return result"
      ],
      "id": "6705e416",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efdf86e5",
        "outputId": "c0d972e0-c1d9-4ee1-9797-9f052be23431"
      },
      "source": [
        "run_with_ngrok(app)\n",
        "app.run()"
      ],
      "id": "efdf86e5",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://083a-35-229-149-123.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "127.0.0.1 - - [30/Aug/2021 05:17:17] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "40006_롯데내몸사랑녹차175ml\n",
            "결과: {'class_name': '40006_롯데내몸사랑녹차175ml'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [30/Aug/2021 05:18:19] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Aug/2021 05:18:57] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Aug/2021 05:19:05] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Aug/2021 05:19:08] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "80015_롯데레쓰비카페타임스위트아메리카노240ML\n",
            "결과: {'class_name': '80015_롯데레쓰비카페타임스위트아메리카노240ML'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [30/Aug/2021 05:19:12] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Aug/2021 05:19:17] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "40006_롯데내몸사랑녹차175ml\n",
            "결과: {'class_name': '40006_롯데내몸사랑녹차175ml'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [30/Aug/2021 05:19:20] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Aug/2021 05:19:22] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Aug/2021 05:19:23] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Aug/2021 05:19:46] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Aug/2021 05:21:56] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Aug/2021 05:22:05] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "40006_롯데내몸사랑녹차175ml\n",
            "결과: {'class_name': '40006_롯데내몸사랑녹차175ml'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [30/Aug/2021 05:22:10] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [30/Aug/2021 05:23:10] \"\u001b[37mPOST /list HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd8a98f8"
      },
      "source": [
        ""
      ],
      "id": "dd8a98f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ec11c64"
      },
      "source": [
        ""
      ],
      "id": "4ec11c64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5036a8a"
      },
      "source": [
        ""
      ],
      "id": "c5036a8a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b3f595f"
      },
      "source": [
        ""
      ],
      "id": "0b3f595f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b222162"
      },
      "source": [
        ""
      ],
      "id": "4b222162",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e217986"
      },
      "source": [
        ""
      ],
      "id": "1e217986",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "043692f6"
      },
      "source": [
        ""
      ],
      "id": "043692f6",
      "execution_count": null,
      "outputs": []
    }
  ]
}